[
  {
    "objectID": "ed.html",
    "href": "ed.html",
    "title": "ed, the standard text editor",
    "section": "",
    "text": "ed, the standard text editor\nIn order to understand how llms.txt can be used with editors and IDEs, let’s look at how ed, the standard text editor, could work (assuming it’s updated to use this proposal). In our example we will look at how the user might then tell ed to retrieve the LLM docs from docs.fastht.ml, and then use the results to write a simple FastHTML web app.\nEven if you use a non-standard editor or IDE such as vscode, Cursor, vim, or Emacs, your software’s interaction with /llms.txt would look similar to this general approach.\n$ ed\n* H\nOur user starts ed and enables helpful error messages (just for the purpose of this walkthru - obviously a real ed user doesn’t need “helpful error messages”).\n* L docs.fastht.ml\nChecking for /llms.txt at docs.fastht.ml...\nFound /llms.txt. Parsing...\nFetching URLs from \"Docs\" section...  Fetching URLs from \"Examples\" section...\nSkipping \"Optional\" section for brevity.\nCreating XML-based context for Claude...  Context created and loaded.\nThe user invokes the hypothetical L (load) command, which in this LLM-enhanced version of ed retrieves and processes the llms.txt file. ed checks for the file (if it didn’t exist, it would fall back to scraping the HTML of the website the old-fashioned way), parses it, fetches the relevant URLs, and creates an XML-based context suitable for Claude (perhaps an ed config file could be used to choose what LLM to use, and would determine how the context is formatted). All of this happens with the characteristic silence of ed, broken only by these reassuring progress messages.\n* x Create a simple FastHTML app which outputs 'Hello, World!', in a &lt;div&gt;.\nAnalyzing context and prompt...\nGenerating FastHTML app...\nApp written to buffer.\nNext, our user invokes the hypothetical x (eXecute AI) command, providing instructions for the LLM to create a simple FastHTML app. In the world of LLM-enhanced ed, this is understood as a request to generate code based on the given prompt and the previously loaded context.\n* n\n5\n* p\nfrom fasthtml.common import *\napp,rt = fast_app()\n@rt\ndef index(): return div(\"Hello, World!\")\nserve()\nThe editor analyzes the loaded context along with the provided prompt, generates the FastHTML app, and writes it to the buffer. The user then views the generated app line count (n) and contents (p), marveling at how much functionality is packed into those 5 lines.\n*w hello_world.py\n5\n*q\nFinally, our user saves the app to a file and quits ed, presumably to run their new FastHTML app and reflect on the unexpected productivity boost provided by their trusty line editor.",
    "crumbs": [
      "Editors and IDEs",
      "`ed`, the standard text editor"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Python module & CLI",
    "section": "",
    "text": "Given an llms.txt file, this provides a CLI and Python API to parse the file and create an XML context file from it. The input file should follow this format:",
    "crumbs": [
      "Code",
      "Python module & CLI"
    ]
  },
  {
    "objectID": "intro.html#install",
    "href": "intro.html#install",
    "title": "Python module & CLI",
    "section": "Install",
    "text": "Install\npip install llms-txt",
    "crumbs": [
      "Code",
      "Python module & CLI"
    ]
  },
  {
    "objectID": "intro.html#how-to-use",
    "href": "intro.html#how-to-use",
    "title": "Python module & CLI",
    "section": "How to use",
    "text": "How to use\n\nCLI\nAfter installation, llms_txt2ctx is available in your terminal.\nTo get help for the CLI:\nllms_txt2ctx -h\nTo convert an llms.txt file to XML context and save to llms.md:\nllms_txt2ctx llms.txt &gt; llms.md\nPass --optional True to add the ‘optional’ section of the input file.\n\n\nPython module\n\nfrom llms_txt import *\n\n\nsamp = Path('llms-sample.txt').read_text()\n\nUse parse_llms_file to create a data structure with the sections of an llms.txt file (you can also add optional=True if needed):\n\nparsed = parse_llms_file(samp)\nlist(parsed)\n\n['title', 'summary', 'info', 'sections']\n\n\n\nparsed.title,parsed.summary\n\n('FastHTML',\n 'FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore\\'s `FT` \"FastTags\" into a library for creating server-rendered hypermedia applications.')\n\n\n\nlist(parsed.sections)\n\n['Docs', 'Examples', 'Optional']\n\n\n\nparsed.sections.Optional[0]\n\n{ 'desc': 'A subset of the Starlette documentation useful for FastHTML '\n          'development.',\n  'title': 'Starlette full documentation',\n  'url': 'https://gist.githubusercontent.com/jph00/809e4a4808d4510be0e3dc9565e9cbd3/raw/9b717589ca44cedc8aaf00b2b8cacef922964c0f/starlette-sml.md'}\n\n\nUse create_ctx to create an LLM context file with XML sections, suitable for systems such as Claude (this is what the CLI calls behind the scenes).\n\nctx = create_ctx(samp)\n\n\nprint(ctx[:300])\n\n&lt;project title=\"FastHTML\" summary='FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore&#39;s `FT` \"FastTags\" into a library for creating server-rendered hypermedia applications.'&gt;\nRemember:\n\n- Use `serve()` for running uvicorn (`if __name__ == \"__main__\"` is not\n\n\n\n\nImplementation and tests\nTo show how simple it is to parse llms.txt files, here’s a complete parser in &lt;20 lines of code with no dependencies:\nfrom pathlib import Path\nimport re,itertools\n\ndef chunked(it, chunk_sz):\n    it = iter(it)\n    return iter(lambda: list(itertools.islice(it, chunk_sz)), [])\n\ndef parse_llms_txt(txt):\n    \"Parse llms.txt file contents in `txt` to a `dict`\"\n    def _p(links):\n        link_pat = '-\\s*\\[(?P&lt;title&gt;[^\\]]+)\\]\\((?P&lt;url&gt;[^\\)]+)\\)(?::\\s*(?P&lt;desc&gt;.*))?'\n        return [re.search(link_pat, l).groupdict()\n                for l in re.split(r'\\n+', links.strip()) if l.strip()]\n\n    start,*rest = re.split(fr'^##\\s*(.*?$)', txt, flags=re.MULTILINE)\n    sects = {k: _p(v) for k,v in dict(chunked(rest, 2)).items()}\n    pat = '^#\\s*(?P&lt;title&gt;.+?$)\\n+(?:^&gt;\\s*(?P&lt;summary&gt;.+?$)$)?\\n+(?P&lt;info&gt;.*)'\n    d = re.search(pat, start.strip(), (re.MULTILINE|re.DOTALL)).groupdict()\n    d['sections'] = sects\n    return d\nWe have provided a test suite in tests/test-parse.py and confirmed that this implementation passes all tests.",
    "crumbs": [
      "Code",
      "Python module & CLI"
    ]
  },
  {
    "objectID": "domains.html",
    "href": "domains.html",
    "title": "llms.txt in Different Domains",
    "section": "",
    "text": "This page has some guidelines and suggestions for how different domains could utilize llms.txt to allow LLMs to better interface with their site if they so choose.\nRemember, when constructing your llms.txt you should “use concise, clear language. When linking to resources, include brief, informative descriptions. Avoid ambiguous terms or unexplained jargon.” Additionally, the best way to determine if your llms.txt works well with LLMs is to test it with them! Here is a minimal way to test Anthropic’s Claude against your llms.txt:\n# /// script\n# requires-python = \"&gt;=3.8\"\n# dependencies = [\n#     \"claudette\",\n#     \"llms-txt\",\n#     \"requests\",\n# ]\n# ///\nfrom claudette import *\nfrom llms_txt import create_ctx\n\nimport requests\n\nmodel = models[1] # Sonnet 3.5\nchat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n\nurl = 'your_url/llms.txt'\ntext = requests.get(url).text\nllm_ctx = create_ctx(text)\nchat(llm_ctx + '\\n\\nThe above is necessary context for the conversation.')\n\nwhile True:\n    msg = input('Your question about the site: ')\n    res = chat(msg)\n    print('From Claude:', contents(res))\nThe above script utilizes the relatively new uv syntax for python scripts. If you install uv, you can simply run the above script with uv run test_llms_txt.py and it will handle installing the necessary library dependencies in an isolated python environment. Else you can install the requirements manually and run it like any ordinary python script with python test_llms_txt.py.\n\n\nHere is an example llms.txt that a restaurant could construct for consumption by LLMs:\n# Nate the Great's Grill\n\n&gt; Nate the Great's Grill is a popular destination off of Sesame Street that has been serving the community for over 20 years. We offer the best BBQ for a great price.\n\nHere are our weekly hours:\n\n- Monday - Friday: 9am - 9pm\n- Saturday: 11am - 9pm\n- Sunday: Closed\n\n## Menus\n\n- [Lunch Menu](https://host/lunch.html.md): Our lunch menu served from 11am to 4pm every day.\n- [Dinner Menu](https://host/dinner.html.md): Our dinner menu served from 4pm to 9pm every day.\n\n## Optional\n\n- [Dessert Mneu](https://host/dessert.md): A subset of the Starlette docs\nAnd here is an example lunch menu taken from Franklin’s BBQ:\n## By The Pound\n\n| Item              | Price         |\n| --------------    | -----------   |\n| Brisket           | 34            |\n| Pork Spare Ribs   | 30            |\n| Pulled Pork       | 28            |\n\n## Drinks\n\n| Item              | Price         |\n| --------------    | -----------   |\n| Iced Tea          | 3             |\n| Mexican Coke      | 3             |\n\n## Sides\n\n| Item              | Price         |\n| --------------    | -----------   |\n| Potato Salad      | 4             |\n| Slaw              | 4             |",
    "crumbs": [
      "Guidlines",
      "llms.txt in Different Domains"
    ]
  },
  {
    "objectID": "domains.html#restaurants",
    "href": "domains.html#restaurants",
    "title": "llms.txt in Different Domains",
    "section": "",
    "text": "Here is an example llms.txt that a restaurant could construct for consumption by LLMs:\n# Nate the Great's Grill\n\n&gt; Nate the Great's Grill is a popular destination off of Sesame Street that has been serving the community for over 20 years. We offer the best BBQ for a great price.\n\nHere are our weekly hours:\n\n- Monday - Friday: 9am - 9pm\n- Saturday: 11am - 9pm\n- Sunday: Closed\n\n## Menus\n\n- [Lunch Menu](https://host/lunch.html.md): Our lunch menu served from 11am to 4pm every day.\n- [Dinner Menu](https://host/dinner.html.md): Our dinner menu served from 4pm to 9pm every day.\n\n## Optional\n\n- [Dessert Mneu](https://host/dessert.md): A subset of the Starlette docs\nAnd here is an example lunch menu taken from Franklin’s BBQ:\n## By The Pound\n\n| Item              | Price         |\n| --------------    | -----------   |\n| Brisket           | 34            |\n| Pork Spare Ribs   | 30            |\n| Pulled Pork       | 28            |\n\n## Drinks\n\n| Item              | Price         |\n| --------------    | -----------   |\n| Iced Tea          | 3             |\n| Mexican Coke      | 3             |\n\n## Sides\n\n| Item              | Price         |\n| --------------    | -----------   |\n| Potato Salad      | 4             |\n| Slaw              | 4             |",
    "crumbs": [
      "Guidlines",
      "llms.txt in Different Domains"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The /llms.txt file",
    "section": "",
    "text": "Today websites are not just used to provide information to people, but they are also used to provide information to large language models. For instance, language models are often used to enhance development environments used by coders, with many systems including an option to ingest information about programming libraries and APIs from website documentation.\nProviding information for language models is a little different to providing information for humans, although there is plenty of overlap. Language models generally like to have information in a more concise form. This can be more similar to what a human expert would want to read. Language models can ingest a lot of information quickly, so it can be helpful to have a single place where all of the key information can be collated—not for training (since training generally involved scraping all pages in all readable formats), but for helping users accessing the site via AI helpers.\nContext windows are too small to handle most websites in their entirety, and converting HTML pages with complex navigation, ads, Javascript, etc into LLM-friendly plain text documents is difficult and imprecise. Therefore it would be helpful if there was a way to identify the most important information to provide to AI helpers, in the most appropriate form."
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "The /llms.txt file",
    "section": "",
    "text": "Today websites are not just used to provide information to people, but they are also used to provide information to large language models. For instance, language models are often used to enhance development environments used by coders, with many systems including an option to ingest information about programming libraries and APIs from website documentation.\nProviding information for language models is a little different to providing information for humans, although there is plenty of overlap. Language models generally like to have information in a more concise form. This can be more similar to what a human expert would want to read. Language models can ingest a lot of information quickly, so it can be helpful to have a single place where all of the key information can be collated—not for training (since training generally involved scraping all pages in all readable formats), but for helping users accessing the site via AI helpers.\nContext windows are too small to handle most websites in their entirety, and converting HTML pages with complex navigation, ads, Javascript, etc into LLM-friendly plain text documents is difficult and imprecise. Therefore it would be helpful if there was a way to identify the most important information to provide to AI helpers, in the most appropriate form."
  },
  {
    "objectID": "index.html#proposal",
    "href": "index.html#proposal",
    "title": "The /llms.txt file",
    "section": "Proposal",
    "text": "Proposal\n\n\n\nllms.txt logo\n\n\nWe propose that those interested in providing LLM-friendly content add a /llms.txt file to their site. This is a markdown file that provides brief background information and guidance, along with links to markdown files (which can also link to external sites) providing more detailed information. This can be used, for instance, in order to provide information necessary for coders to use a library, or as part of research to learn about a person or organization and so forth. You are free to use the llms.txt logo on your site to indicate your support if you wish.\nllms.txt markdown is human and LLM readable, but is also in a precise format allowing fixed processing methods (i.e. classical programming techniques such as parsers and regex). For instance, there is an llms-txt project providing a CLI and Python module for parsing llms.txt files and generating LLM context from them. There is also a sample JavaScript implementation.\nWe furthermore propose that pages on websites that have information that might be useful for LLMs to read provide a clean markdown version of those pages at the same URL as the original page, but with .md appended. (URLs without file names should append index.html.md instead.)\nThe FastHTML project follows these two proposals for its documentation. For instance, here is the FastHTML docs llms.txt. And here is an example of a regular HTML docs page, along with exact same URL but with a .md extension. Note that all nbdev projects now create .md versions of all pages by default, and all Answer.AI and fast.ai software projects using nbdev have had their docs regenerated with this feature—for instance, see the markdown version of fastcore’s docments module.\nThis proposal does not include any particular recommendation for how to process the file, since it will depend on the application. For example, FastHTML automatically builds a new version of two markdown files including the contents of the linked URLs, using an XML-based structure suitable for use in LLMs such as Claude. The two files are: llms-ctx.txt, which does not include the optional URLs, and llms-ctx-full.txt, which does include them. They are created using the llms_txt2ctx command line application, and the FastHTML documentation includes information for users about how to use them.\nllms.txt files can be used in various scenarios. For software libraries, they can provide a structured overview of documentation, making it easier for LLMs to locate specific features or usage examples. In corporate websites, they can outline organizational structure and key information sources. Information about new legislation and necessary background and context could be curated in an llms.txt file to help stakeholders understand it.\nllms.txt files can be adapted for various domains. Personal portfolio or CV websites could use them to help answer questions about an individual. In e-commerce, they could outline product categories and policies. Educational institutions might use them to summarize course offerings and resources."
  },
  {
    "objectID": "index.html#format",
    "href": "index.html#format",
    "title": "The /llms.txt file",
    "section": "Format",
    "text": "Format\nAt the moment the most widely and easily understood format for language models is Markdown. Simply showing where key Markdown files can be found is a great first step. Providing some basic structure helps a language model to find where the information it needs can come from.\nThe llms.txt file is unusual in that it uses Markdown to structure the information rather than a classic structured format such as XML. The reason for this is that we expect many of these files to be read by language models and agents. Having said that, the information in llms.txt follows a specific format and can be read using standard programmatic-based tools.\nThe llms.txt file spec is for files located in the root path /llms.txt of a website (or, optionally, in a subpath). A file following the spec contains the following sections as markdown, in the specific order:\n\nAn H1 with the name of the project or site. This is the only required section\nA blockquote with a short summary of the project, containing key information necessary for understanding the rest of the file\nZero or more markdown sections (e.g. paragraphs, lists, etc) of any type except headings, containing more detailed information about the project and how to interpret the provided files\nZero or more markdown sections delimited by H2 headers, containing “file lists” of URLs where further detail is available\n\nEach “file list” is a markdown list, containing a required markdown hyperlink [name](url), then optionally a : and notes about the file.\n\n\nHere is a mock example:\n# Title\n\n&gt; Optional description goes here\n\nOptional details go here\n\n## Section name\n\n- [Link title](https://link_url): Optional link details\n\n## Optional\n\n- [Link title](https://link_url)\nNote that the “Optional” section has a special meaning—if it’s included, the URLs provided there can be skipped if a shorter context is needed. Use it for secondary information which can often be skipped."
  },
  {
    "objectID": "index.html#existing-standards",
    "href": "index.html#existing-standards",
    "title": "The /llms.txt file",
    "section": "Existing standards",
    "text": "Existing standards\nllms.txt is designed to coexist with current web standards. While sitemaps list all pages for search engines, llms.txt offers a curated overview for LLMs. It can complement robots.txt by providing context for allowed content. The file can also reference structured data markup used on the site, helping LLMs understand how to interpret this information in context.\nThe approach of standardising on a path for the file follows the approach of /robots.txt and /sitemap.xml. robots.txt and llms.txt have different purposes—robots.txt is generally used to let automated tools what access to a site is considered acceptable, such as for search indexing bots. On the other hand, llms.txt information will often be used on demand when a user explicitly requesting information about a topic, such as when including a coding library’s documentation in a project, or when asking a chat bot with search functiontionality for information. Our expectation is that llms.txt will mainly be useful for inference, i.e. at the time a user is seeking assistance, as opposed to for training. However, perhaps if llms.txt usage becomes widespread, future training runs could take advantage of the information in llms.txt files too.\nsitemap.xml is a list of all the indexable human-readable information available on a site. This isn’t a substitute for llms.txt since it:\n\nOften won’t have the LLM-readable versions of pages listed\nDoesn’t include URLs to external sites, even although they might be helpful to understand the information\nWill generally cover documents that in aggregate will be too large to fit in an LLM context window, and will include a lot of information that isn’t necessary to understand the site."
  },
  {
    "objectID": "index.html#example",
    "href": "index.html#example",
    "title": "The /llms.txt file",
    "section": "Example",
    "text": "Example\nHere’s an example of llms.txt, in this case a cut down version of the file used for the FastHTML project (see also the full version:\n# FastHTML\n\n&gt; FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore's `FT` \"FastTags\" into a library for creating server-rendered hypermedia applications.\n\nImportant notes:\n\n- Although parts of its API are inspired by FastAPI, it is *not* compatible with FastAPI syntax and is not targeted at creating API services\n- FastHTML is compatible with JS-native web components and any vanilla JS library, but not with React, Vue, or Svelte.\n\n## Docs\n\n- [FastHTML quick start](https://docs.fastht.ml/path/quickstart.html.md): A brief overview of many FastHTML features\n- [HTMX reference](https://raw.githubusercontent.com/path/reference.md): Brief description of all HTMX attributes, CSS classes, headers, events, extensions, js lib methods, and config options\n\n## Examples\n\n- [Todo list application](https://raw.githubusercontent.com/path/adv_app.py): Detailed walk-thru of a complete CRUD app in FastHTML showing idiomatic use of FastHTML and HTMX patterns.\n\n## Optional\n\n- [Starlette full documentation](https://gist.githubusercontent.com/path/starlette-sml.md): A subset of the Starlette documentation useful for FastHTML development.\nTo create effective llms.txt files, consider these guidelines: Use concise, clear language. When linking to resources, include brief, informative descriptions. Avoid ambiguous terms or unexplained jargon. Run a tool that expands your llms.txt file into an LLM context file and test a number of language models to see if they can answer questions about your content."
  },
  {
    "objectID": "index.html#next-steps",
    "href": "index.html#next-steps",
    "title": "The /llms.txt file",
    "section": "Next steps",
    "text": "Next steps\nThe llms.txt specification is open for community input. A GitHub repository hosts this informal overview, allowing for version control and public discussion. A community discord channel is available for sharing implementation experiences and discussing best practices."
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Python source",
    "section": "",
    "text": "The llms.txt file spec is for files located in the path llms.txt of a website (or, optionally, in a subpath). llms-sample.txt is a simple example. A file following the spec contains the following sections as markdown, in the specific order:\n\nAn H1 with the name of the project or site. This is the only required section\nA blockquote with a short summary of the project, containing key information necessary for understanding the rest of the file\nZero or more markdown sections (e.g. paragraphs, lists, etc) of any type, except headings, containing more detailed information about the project and how to interpret the provided files\nZero or more markdown sections delimited by H2 headers, containing “file lists” of URLs where further detail is available\n\nEach “file list” is a markdown list, containing a required markdown hyperlink [name](url), then optionally a : and notes about the file.\n\n\nHere’s the start of a sample llms.txt file we’ll use for testing:\n\nsamp = Path('llms-sample.txt').read_text()\nprint(samp[:480])\n\n# FastHTML\n\n&gt; FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore's `FT` \"FastTags\" into a library for creating server-rendered hypermedia applications.\n\nRemember:\n\n- Use `serve()` for running uvicorn (`if __name__ == \"__main__\"` is not needed since it's automatic)\n- When a title is needed with a response, use `Titled`; note that that already wraps children in `Container`, and already includes both the meta title as well as the H1 element",
    "crumbs": [
      "Code",
      "Python source"
    ]
  },
  {
    "objectID": "core.html#introduction",
    "href": "core.html#introduction",
    "title": "Python source",
    "section": "",
    "text": "The llms.txt file spec is for files located in the path llms.txt of a website (or, optionally, in a subpath). llms-sample.txt is a simple example. A file following the spec contains the following sections as markdown, in the specific order:\n\nAn H1 with the name of the project or site. This is the only required section\nA blockquote with a short summary of the project, containing key information necessary for understanding the rest of the file\nZero or more markdown sections (e.g. paragraphs, lists, etc) of any type, except headings, containing more detailed information about the project and how to interpret the provided files\nZero or more markdown sections delimited by H2 headers, containing “file lists” of URLs where further detail is available\n\nEach “file list” is a markdown list, containing a required markdown hyperlink [name](url), then optionally a : and notes about the file.\n\n\nHere’s the start of a sample llms.txt file we’ll use for testing:\n\nsamp = Path('llms-sample.txt').read_text()\nprint(samp[:480])\n\n# FastHTML\n\n&gt; FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore's `FT` \"FastTags\" into a library for creating server-rendered hypermedia applications.\n\nRemember:\n\n- Use `serve()` for running uvicorn (`if __name__ == \"__main__\"` is not needed since it's automatic)\n- When a title is needed with a response, use `Titled`; note that that already wraps children in `Container`, and already includes both the meta title as well as the H1 element",
    "crumbs": [
      "Code",
      "Python source"
    ]
  },
  {
    "objectID": "core.html#reading",
    "href": "core.html#reading",
    "title": "Python source",
    "section": "Reading",
    "text": "Reading\nWe’ll implement parse_llms_file to pull out the sections of llms.txt into a simple data structure.\n\nsource\n\nsearch\n\n search (pat, txt, flags=0)\n\nDictionary of matched groups in pat within txt\n\nsource\n\n\nnamed_re\n\n named_re (nm, pat)\n\nPattern to match pat in a named capture group\n\nsource\n\n\nopt_re\n\n opt_re (s)\n\nPattern to optionally match s\nWe’ll work “outside in” so we can test the innermost matches as we go.\n\n\nParse links\n\nlink = '- [FastHTML quick start](https://docs.fastht.ml/tutorials/quickstart_for_web_devs.html.md): A brief overview of FastHTML features'\n\nParse the first part of link into a dict\n\ntitle = named_re('title', r'[^\\]]+')\npat =  fr'-\\s*\\[{title}\\]'\nsearch(pat, samp)\n\n{'title': 'internal docs - ed'}\n\n\nDo the next bit.\n\nurl = named_re('url', r'[^\\)]+')\npat += fr'\\({url}\\)'\nsearch(pat, samp)\n\n{'title': 'internal docs - ed', 'url': 'https://llmstxt.org/ed.html'}\n\n\nDo the final bit. Note it’s optional.\n\ndesc = named_re('desc', r'.*')\npat += opt_re(fr':\\s*{desc}')\nsearch(pat, link)\n\n{'title': 'FastHTML quick start',\n 'url': 'https://docs.fastht.ml/tutorials/quickstart_for_web_devs.html.md',\n 'desc': 'A brief overview of FastHTML features'}\n\n\nCombine those sections into a function parse_link(txt)\n\nsource\n\n\nparse_link\n\n parse_link (txt)\n\nParse a link section from llms.txt\n\nparse_link(link)\n\n{'title': 'FastHTML quick start',\n 'url': 'https://docs.fastht.ml/tutorials/quickstart_for_web_devs.html.md',\n 'desc': 'A brief overview of FastHTML features'}\n\n\n\nparse_link('-[foo](http://foo)')\n\n{'title': 'foo', 'url': 'http://foo', 'desc': None}\n\n\n\n\nParse sections\n\nsections = '''First bit.\n\n## S1\n\n-[foo](http://foo)\n- [foo2](http://foo2): stuff\n\n## S2\n\n- [foo3](http://foo3)'''\n\n\nstart,*rest = re.split(fr'^##\\s*(.*?$)', sections, flags=re.MULTILINE)\nstart\n\n'First bit.\\n\\n'\n\n\n\nrest\n\n['S1',\n '\\n\\n-[foo](http://foo)\\n- [foo2](http://foo2): stuff\\n\\n',\n 'S2',\n '\\n\\n- [foo3](http://foo3)']\n\n\nConcisely create a dict from the pairs in rest.\n\nd = dict(chunked(rest, 2))\nd\n\n{'S1': '\\n\\n-[foo](http://foo)\\n- [foo2](http://foo2): stuff\\n\\n',\n 'S2': '\\n\\n- [foo3](http://foo3)'}\n\n\n\nlinks = d['S1']\nlinks.strip()\n\n'-[foo](http://foo)\\n- [foo2](http://foo2): stuff'\n\n\nParse links into a list of links. There can be multiple newlines between them.\n\n_parse_links(links)\n\n[{'title': 'foo', 'url': 'http://foo', 'desc': None},\n {'title': 'foo2', 'url': 'http://foo2', 'desc': 'stuff'}]\n\n\nCreate a function that uses the above steps to parse an llms.txt into start and a dict with keys like d and parsed list of links as values.\n\nstart, sects = _parse_llms(samp)\nstart\n\n'# FastHTML\\n\\n&gt; FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore\\'s `FT` \"FastTags\" into a library for creating server-rendered hypermedia applications.\\n\\nRemember:\\n\\n- Use `serve()` for running uvicorn (`if __name__ == \"__main__\"` is not needed since it\\'s automatic)\\n- When a title is needed with a response, use `Titled`; note that that already wraps children in `Container`, and already includes both the meta title as well as the H1 element.'\n\n\n\ntitle = named_re('title', r'.+?$')\nsumm = named_re('summary', '.+?$')\nsumm_pat = opt_re(fr\"^&gt;\\s*{summ}$\")\ninfo = named_re('info', '.*')\n\n\npat = fr'^#\\s*{title}\\n+{summ_pat}\\n+{info}'\nsearch(pat, start, (re.MULTILINE|re.DOTALL))\n\n{'title': 'FastHTML',\n 'summary': 'FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore\\'s `FT` \"FastTags\" into a library for creating server-rendered hypermedia applications.',\n 'info': 'Remember:\\n\\n- Use `serve()` for running uvicorn (`if __name__ == \"__main__\"` is not needed since it\\'s automatic)\\n- When a title is needed with a response, use `Titled`; note that that already wraps children in `Container`, and already includes both the meta title as well as the H1 element.'}\n\n\nLet’s finish it off!\n\nsource\n\n\nparse_llms_file\n\n parse_llms_file (txt)\n\nParse llms.txt file contents in txt to an AttrDict\n\nllmsd = parse_llms_file(samp)\nllmsd.summary\n\n'FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore\\'s `FT` \"FastTags\" into a library for creating server-rendered hypermedia applications.'\n\n\n\nllmsd.sections.Examples\n\n(#1) [{'title': 'Todo list application', 'url': 'https://raw.githubusercontent.com/AnswerDotAI/fasthtml/main/examples/adv_app.py', 'desc': 'Detailed walk-thru of a complete CRUD app in FastHTML showing idiomatic use of FastHTML and HTMX patterns.'}]",
    "crumbs": [
      "Code",
      "Python source"
    ]
  },
  {
    "objectID": "core.html#xml-conversion",
    "href": "core.html#xml-conversion",
    "title": "Python source",
    "section": "XML conversion",
    "text": "XML conversion\nFor some LLMs such as Claude, XML format is preferred, so we’ll provide a function to create that format.\n\nsource\n\nget_doc_content\n\n get_doc_content (url)\n\nFetch content from local file if in nbdev repo.\n\nsource\n\n\nmk_ctx\n\n mk_ctx (d, optional=True, n_workers=None)\n\nCreate a Project with a Section for each H2 part in d, optionally skipping the ‘optional’ section.\n\nctx = mk_ctx(llmsd)\nprint(to_xml(ctx, do_escape=False)[:260]+'...')\n\n&lt;project title=\"FastHTML\" summary='FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore&#39;s `FT` \"FastTags\" into a library for creating server-rendered hypermedia applications.'&gt;Remember:\n\n- Use `serve()` for running uvic...\n\n\n\nsource\n\n\nget_sizes\n\n get_sizes (ctx)\n\nGet the size of each section of the LLM context\n\nget_sizes(ctx)\n\n{'docs': {'internal docs - ed': 34464,\n  'FastHTML quick start': 27383,\n  'HTMX reference': 26812,\n  'Starlette quick guide': 7936},\n 'examples': {'Todo list application': 18558},\n 'optional': {'Starlette full documentation': 48331}}\n\n\n\nPath('../fasthtml.md').write_text(to_xml(ctx, do_escape=False))\n\n164662\n\n\n\nsource\n\n\ncreate_ctx\n\n create_ctx (txt, optional=False, n_workers=None)\n\nA Project with a Section for each H2 part in txt, optionally skipping the ‘optional’ section.\n\nsource\n\n\nllms_txt2ctx\n\n llms_txt2ctx (fname:str, optional:&lt;function bool_arg&gt;=False,\n               n_workers:int=None, save_nbdev_fname:str=None)\n\nPrint a Project with a Section for each H2 part in file read from fname, optionally skipping the ‘optional’ section.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\n\nFile name to read\n\n\noptional\nbool_arg\nFalse\nInclude ‘optional’ section?\n\n\nn_workers\nint\nNone\nNumber of threads to use for parallel downloading\n\n\nsave_nbdev_fname\nstr\nNone\nsave output to nbdev {docs_path} instead of emitting to stdout\n\n\n\n\n!llms_txt2ctx llms-sample.txt &gt; ../fasthtml.md",
    "crumbs": [
      "Code",
      "Python source"
    ]
  }
]